{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb9e126c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import random\n",
    "from mlxtend.frequent_patterns import apriori, association_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d7b2d8",
   "metadata": {},
   "source": [
    "## 1. Simulate Transaction Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec76833",
   "metadata": {},
   "source": [
    "#### Marilyn: \n",
    "- Imported the pandas and random librabries\n",
    "- Simulated the transactions\n",
    "- Saved the transactions to a csv file called  \"'supermarket_transactions.csv'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8384a91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the pool of items that can appear in a transaction\n",
    "item_pool = ['Milk', 'Eggs', 'Butter', 'Cheese', 'Bananas', 'Bread', 'Apples', 'Chicken','pork', 'beef', 'strawberries','pineapples', 'watermelon','lemon','melon', 'avocadoes', 'dragonfruit', 'orange', 'kiwi', 'flour', 'rice', 'sugar','salt','noodles','potato','onion','fruitjuice','garlic', 'okra','cucumbers']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19851ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cheese, Milk, noodles, pork, Chicken, onion, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cheese, sugar, noodles, orange, Butter, kiwi, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Milk, Butter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chicken, dragonfruit, flour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>orange, Apples</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Transaction\n",
       "0  Cheese, Milk, noodles, pork, Chicken, onion, B...\n",
       "1  Cheese, sugar, noodles, orange, Butter, kiwi, ...\n",
       "2                                       Milk, Butter\n",
       "3                        Chicken, dragonfruit, flour\n",
       "4                                     orange, Apples"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for reproducibility\n",
    "random.seed(42)\n",
    " # List to hold transactions\n",
    "transactions = []\n",
    "# Generate 3000 fake transactions, each with 2â€“7 random items and store them in a list\n",
    "for _ in range(3000): \n",
    "    num_items = random.randint(2, 7) \n",
    "    transaction = random.sample(item_pool, num_items)\n",
    "    transactions.append(transaction) \n",
    "\n",
    "# Convert the transactions into a DataFrame where each row = one transaction and items separated by comma)\n",
    "transactions_df = pd.DataFrame({'Transaction': [', '.join(items) for items in transactions]})\n",
    "\n",
    "# Save to CSV\n",
    "transactions_df.to_csv('supermarket_transactions.csv', index=False)\n",
    "# Display the first few transactions\n",
    "\n",
    "transactions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea67bdb5",
   "metadata": {},
   "source": [
    "## 2. Preprocessing: One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc643aee",
   "metadata": {},
   "source": [
    "CHAD:\n",
    "\n",
    "1.Extracted all unique items across all transactions using a set and sorted() to create a consistent column order.\n",
    "\n",
    "2.Created a one-hot encoded structure, where:\n",
    "\n",
    "    -Each row represents a single transaction.\n",
    "    -Each column represents an item.\n",
    "    -Cell values are True if the item is present in that transaction, otherwise False.\n",
    "\n",
    "3.Stored the encoded transactions as a list of dictionaries (encoded_data), each mapping item names to boolean values.\n",
    "\n",
    "4.Converted the list of dictionaries into a Pandas DataFrame (df), suitable for input into the mlxtend.frequent_patterns.apriori() algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d07f2237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to one-hot encoded DataFrame\n",
    "all_items = sorted(set(item for transaction in transactions for item in transaction)) \n",
    "encoded_data = []\n",
    "for transaction in transactions:\n",
    "    encoded_data.append({item: (item in transaction) for item in all_items})\n",
    "df = pd.DataFrame(encoded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01718f78",
   "metadata": {},
   "source": [
    "##  3. Generate Frequent Itemsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a617203d",
   "metadata": {},
   "source": [
    "Hetal:\n",
    "\n",
    "- Used 'apriori()' from 'mlxtend.frequent_patterns' to generate itemsets with min_support = 0.05.\n",
    "\n",
    "- Displayed and exported the **top 10 itemsets.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfa3ca0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most Frequent Itemsets:\n",
      "      support      itemsets\n",
      "28  0.170000       (sugar)\n",
      "4   0.162333      (Cheese)\n",
      "8   0.161000   (avocadoes)\n",
      "25  0.159333        (rice)\n",
      "1   0.159000     (Bananas)\n",
      "26  0.156667        (salt)\n",
      "16  0.154333       (lemon)\n",
      "18  0.154000     (noodles)\n",
      "17  0.154000       (melon)\n",
      "29  0.152667  (watermelon)\n"
     ]
    }
   ],
   "source": [
    "# Hetal: \n",
    "# Generate frequent itemsets with a minimum support threshold of 0.05\n",
    "frequent_itemsets = apriori(df, min_support=0.05, use_colnames=True) \n",
    "\n",
    "# Sort by support in descending order and displaying top 10\n",
    "top_10_itemsets = frequent_itemsets.sort_values(by='support', ascending=False).head(10)\n",
    "\n",
    "# Displaying the top 10 frequent itemsets\n",
    "print(\"Top 10 most Frequent Itemsets:\\n\", top_10_itemsets)\n",
    "\n",
    "# Export 'top_10_itemsets' to CSV\n",
    "top_10_itemsets.to_csv('frequent_itemsets.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f928d9",
   "metadata": {},
   "source": [
    "### 4: Identify Closed Frequent Itemsets  \n",
    "Rita:\n",
    "\n",
    "- A *Closed Frequent Itemset* is one where **no proper superset has the same support**.  \n",
    "- To identify closed itemsets, compare each frequent itemset against all others.  \n",
    "- If a larger itemset existed that contained the current one *and* had the same support, it was excluded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38675055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed itemsets saved: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemset</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sugar</td>\n",
       "      <td>0.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>0.162333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avocadoes</td>\n",
       "      <td>0.161000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rice</td>\n",
       "      <td>0.159333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bananas</td>\n",
       "      <td>0.159000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     itemset   support\n",
       "0      sugar  0.170000\n",
       "1     Cheese  0.162333\n",
       "2  avocadoes  0.161000\n",
       "3       rice  0.159333\n",
       "4    Bananas  0.159000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load frequent itemsets from CSV\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"frequent_itemsets.csv\")\n",
    "\n",
    "# Clean and convert the 'itemsets' column from string to list of items\n",
    "df['items'] = df['itemsets'].apply(lambda x: sorted(x.replace(\"frozenset({\", \"\").replace(\"})\", \"\").replace(\"'\", \"\").split(', ')))\n",
    "\n",
    "# Initialize list to store closed itemsets\n",
    "closed_itemsets = []\n",
    "\n",
    "# Compare each itemset with all others\n",
    "for i, row_i in df.iterrows():\n",
    "    items_i = set(row_i['items'])\n",
    "    support_i = row_i['support']\n",
    "    is_closed = True\n",
    "\n",
    "    for j, row_j in df.iterrows():\n",
    "        items_j = set(row_j['items'])\n",
    "        support_j = row_j['support']\n",
    "\n",
    "        # Itemset is not closed if a proper superset has the same support\n",
    "        if items_i < items_j and support_i == support_j:\n",
    "            is_closed = False\n",
    "            break\n",
    "\n",
    "    if is_closed:\n",
    "        closed_itemsets.append((','.join(items_i), support_i))\n",
    "\n",
    "# Save closed itemsets to CSV\n",
    "closed_df = pd.DataFrame(closed_itemsets, columns=['itemset', 'support'])\n",
    "closed_df.to_csv(\"closed_itemsets.csv\", index=False)\n",
    "\n",
    "# Step 6: Show confirmation and preview\n",
    "print(\"Closed itemsets saved:\", len(closed_df))\n",
    "closed_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44781cc5",
   "metadata": {},
   "source": [
    "### 5: Identify Maximal Frequent Itemsets  \n",
    "Rita:\n",
    "\n",
    "- A *Maximal Frequent Itemset* is one where **no frequent superset exists**.  \n",
    "- To identify maximal itemsets, compare each frequent itemset against all others.  \n",
    "- If a larger itemset existed that contained the current one and was also frequent, it was excluded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83cf63a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.170000</td>\n",
       "      <td>frozenset({'sugar'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.162333</td>\n",
       "      <td>frozenset({'Cheese'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.161000</td>\n",
       "      <td>frozenset({'avocadoes'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.159333</td>\n",
       "      <td>frozenset({'rice'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.159000</td>\n",
       "      <td>frozenset({'Bananas'})</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    support                  itemsets\n",
       "0  0.170000      frozenset({'sugar'})\n",
       "1  0.162333     frozenset({'Cheese'})\n",
       "2  0.161000  frozenset({'avocadoes'})\n",
       "3  0.159333       frozenset({'rice'})\n",
       "4  0.159000    frozenset({'Bananas'})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the frequent itemsets\n",
    "df = pd.read_csv(\"frequent_itemsets.csv\")\n",
    "\n",
    "# Convert string itemsets to Python lists\n",
    "df['items'] = df['itemsets'].apply(lambda x: sorted(eval(x)))\n",
    "\n",
    "maximal_itemsets = []\n",
    "\n",
    "# Check each itemset\n",
    "for i, row in df.iterrows():\n",
    "    is_maximal = True\n",
    "    for j, other_row in df.iterrows():\n",
    "        if i != j:\n",
    "            # Check if this itemset is a subset of another\n",
    "            if set(row['items']).issubset(set(other_row['items'])) and row['support'] <= other_row['support']:\n",
    "                is_maximal = False\n",
    "                break\n",
    "    if is_maximal:\n",
    "        maximal_itemsets.append(row)\n",
    "\n",
    "# Create final DataFrame of maximal itemsets\n",
    "maximal_df = pd.DataFrame(maximal_itemsets)\n",
    "\n",
    "# Drop the helper 'items' column\n",
    "maximal_df = maximal_df.drop(columns=['items'])\n",
    "\n",
    "# Save to CSV\n",
    "maximal_df.to_csv(\"maximal_itemsets.csv\", index=False)\n",
    "\n",
    "# Show top 5\n",
    "maximal_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
